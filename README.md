# DevOps - Compte rendu 

## TP 01 - Docker ‚úàÔ∏è‚úàÔ∏è‚úàÔ∏è

- DockerFile üê≥:

``` yaml
FROM postgres:14.1-alpine

ENV POSTGRES_DB=db \
   POSTGRES_USER=usr \
   POSTGRES_PASSWORD=pwd

```

- Pour build üîß :
```shell
sudo docker build -t tp1/tp1 .
```

- pour lancer le run en d√©tach : üë®‚Äçü¶Ω

```shell
sudo docker run --name tp1 tp1/tp1
```

‚ùì Why should we run the container with a flag -e to give the environment variables? üá∫üá∏

üí° 	 Il faut lancer le container avec le flag -e pour pr√©ciser les variables d'environment. Pour une database, il est obligatoire d'avoir un superuser avec un mot de passe. üá´üá∑

### Connexion √† une base de donn√©e PostGres

- Ajouter un network üï∏Ô∏è
```shell
sudo docker network create app-network
```
- Relancer le container tp1 avec le network ‚ôªÔ∏è

``` shell
sudo docker run --net=app-network -d --name=tp1 tp1/tp1
```

- Adminer üïµÔ∏è‚Äç‚ôÇÔ∏è

```shell
sudo docker run \
    -p "8090:8080" \
    --net=app-network \
    --name=adminer \
    -d \
    adminer
```

### Connexion depuis le navigateur sur le port 8090

- infos de logs üßë‚Äçüíª

```shell
    System:	PostGreSQL
    Server: tp1
    Username: usr
    Password: pwd
    Database: db	
```
‚ùó Les identifiants de connexions sont soit fournies en ligne de commande avec le flag `-e` soit sp√©cifi√© dans le dockerfile.

### Lancement d'une database avec un set de donn√©e:

Tous les scripts copi√©s dans `docker-entrypoint-initdb.d` seront execut√©s. On rajoute donc au Dockerfile üìù: 

```shell
COPY CreateScheme.sql /docker-entrypoint-initdb.d/
COPY InsertData.sql /docker-entrypoint-initdb.d/
```
### Persistance des donn√©es 

Pour persister la donn√©e, il faut utiliser un volume. Pour ce faire il faut pr√©ciser avec le flag `-v`. Il prend 3 param√®tres dont un optionnel:
- Nom du volume
- Chemin o√π le volume sera mont√© dans le container
- Liste d'option (optionnel) 

‚ùì Why do we need a volume to be attached to our postgres container? üá∫üá∏

üí° Il faut un volume attach√© au container afin de persister la donn√©e. Si on d√©truit le container et qu'il n'a pas de volume attach√©, la base de donn√©e est r√©initialis√©e √† son prochain lancement.üá´üá∑

## Backend API

### Java Application

DockerFile üê≥:

```
FROM openjdk:11
COPY ./Main.java /usr/src/
WORKDIR /usr/src/
RUN javac Main.java
CMD ["java", "Main"]
```
Build üîß:

```
sudo docker build -t java/backend . 
```

Run üë®‚Äçü¶Ω : 

```
sudo docker run --name backend java/backend    
```
### Springboot Application

‚ùó Il faut bien exposer les ports docker sinon l'application springboot ne sera pas accessible. 

DockerFile üê≥:
```
# Build
FROM maven:3.8.6-amazoncorretto-17 AS myapp-build
ENV MYAPP_HOME /opt/myapp
WORKDIR $MYAPP_HOME
COPY pom.xml .
COPY src ./src
RUN mvn package -DskipTests

# Run
FROM amazoncorretto:17
ENV MYAPP_HOME /opt/myapp
WORKDIR $MYAPP_HOME
COPY --from=myapp-build $MYAPP_HOME/target/*.jar $MYAPP_HOME/myapp.jar

ENTRYPOINT java -jar myapp.jar
```
Build üîß:
```
sudo docker build -t api/simpleapi .
```

Run üë®‚Äçü¶Ω : 
```
sudo docker run --name=simpleapi -p 8080:8080 api/simpleapi
```

‚ùì Why do we need a multistage build? And explain each step of this dockerfile. üá∫üá∏

üí° Un build multistage est un build qui utilise plusieurs fois l'instruction `FROM`. Chaque `FROM` constitue une √©tape du build. Cela nous permet d'utiliser diff√©rentes bases.üá´üá∑

Dans notre cas, il nous faut d'abord build notre application java en t√©l√©chargeant les d√©pendances maven. On le run ensuite avec le JDK d'amazon.

### Backend API 

Fichiers t√©l√©charg√©s depuis le [git](https://github.com/takima-training/simple-api-student) mis √† disposition.


Le Dockerfile est identique √† celui pr√©c√©demment.

Il faut cependant bien lancer le container dans le r√©seau cr√©e pr√©c√©demment o√π tourne notre base de donn√©e PostGreSQL.

Run üë®‚Äçü¶Ω : 

```
sudo docker run --name=simpleapi-student¬†\
--net=app-network \
-p 8081:8080 \
java/simple-api-student
```

Configuration de l'appli avant le build pour la connexion √† la db: 

Application.yaml: 
```
spring:
  jpa:
    properties:
      hibernate:
        jdbc:
          lob:
            non_contextual_creation: true
    generate-ddl: false
    open-in-view: true
  datasource:
    url: jdbc:postgresql://tp1:5432/db
    username: usr
    password: pwd
    driver-class-name: org.postgresql.Driver
management:
 server:
   add-application-context-header: false
 endpoints:
   web:
     exposure:
       include: health,info,env,metrics,beans,configprops
```
On a acc√®s grace au mapping des calls sur le port 8081 √† la database. ‚úÖ

## HTTP Server

Configuration basique:
On cr√©e un nouveau dossier `public-html` o√π l'on stockera un index.html classique.

DockerFile üê≥:
```
FROM httpd:2.4
COPY ./public-html/ /usr/local/apache2/htdocs/
```
Build üîß:

`sudo docker build -t http/http .`

Run üë®‚Äçü¶Ω :

`sudo docker run -dit --name my-running-app -p 8080:80 http/http`

### Configuration 
Afficher la configuration globale apache:

`sudo docker exec my-running-app cat /usr/local/apache2/conf/httpd.conf`

### Reverse proxy

On cr√©er un fichier de confif √† partir de celui de base :

```
sudo docker exec my-running-app cat /usr/local/apache2/conf/httpd.conf >> httpd.conf
```

On modifie le fichier de conf apache depuis le Dockerfile en rajoutant:
- Le nom du serveur :
`ServerName localhost`
- La config du proxy : 
```
<VirtualHost *:80>
ProxyPreserveHost On
ProxyPass / http://simpleapi-student:8080/
ProxyPassReverse / http://simpleapi-student:8080/
</VirtualHost>
LoadModule proxy_module modules/mod_proxy.so
LoadModule proxy_http_module modules/mod_proxy_http.so
```

Dockerfile :

```
FROM httpd:2.4
COPY ./public-html/ /usr/local/apache2/htdocs/
COPY ./httpd.conf /usr/local/apache2/conf/httpd.conf
```


On rebuild et on relance:

```
sudo docker run --net=app-network --name my-running-app -p 8080:80 http/http
```

‚ùì Why do we need a reverse proxy? üá∫üá∏

üí° Pour ne pas exposer directement le port de notre container. On doit forc√©ment passer par notre front. üá´üá∑

### Link application

Docker compose :

```
version: '3.7'

services:
  db:
    build: database
    container_name: postgres-db
    environment:
      - POSTGRES_DB=db
      - POSTGRES_USER=usr
      - POSTGRES_PASSWORD=pwd
    networks:
      - app-network

  springboot-app:
    build: simple-api-student
    container_name : springboot-app-container
    environment:
      - URL=db:5432
      - POSTGRES_DB=db
      - POSTGRES_USER=usr
      - POSTGRES_PASSWORD=pwd
    networks:
      - app-network
    depends_on:
      - db
      
  my-apache-server:
    build: my-apache-server
    container_name: my-apache-server-container
    ports:
      - "8081:80"
    networks:
      - app-network
    depends_on:
      - springboot-app
networks:
  app-network:
    driver: bridge
```
On met √† jour application.yaml de notre springboot pour prendre en charge les variables d'environnements: 
```
applications.yaml
  datasource:
    url: jdbc:postgresql://${URL}/${POSTGRES_DB}
    username: ${POSTGRES_USER} 
    password: ${POSTGRES_PASSWORD}
```
De m√™me pour le serveur apache, on met √† jour le fichier de conf httpd.conf:
```
ProxyPass / http://springboot-app:8080/
```
ProxyPassReverse / http://springboot-app:8080/

‚ùì Why is docker-compose so important? üá∫üá∏

üí° Car cela permet de lancer & de configurer plusieur docker de mani√®re automatique. üá´üá∑

## Publish

R√©aliser principalement dans le TP 02 avec le d√©ploiement continue.

‚ùì Document your publication commands and published images in dockerhub. üá∫üá∏

üí° On tag les images pour les identifi√©s et on les versionne. Cela nous permettra par la suite de r√©cup√©rer des versions biens sp√©cifiques de nos applications lors de d√©ploiement. üá´üá∑

## TP 02 - Github Action üöÄüöÄüöÄ

### Setup Github Actions

GitHub Action est utilis√© tout au long de ce TP. Il permet de lancer des **`jobs`**, des t√¢ches √† effectu√© lors d'un d√©ploiement. On peut choisir √† quel moment d√©clencher ces actions.

### First steps into the CI World

Il faut cr√©er un workflow, un dossier .github & un sous dossier workflows, contenant les routines qui vont √™tre execut√©s. Cette routine est contenue dans le fichier `main .yml`. 

### Build and test your Application

```bash
mvn clean verify
```

Permet de lancer tous les tests pr√©sent dans le projet pr√©cis√© dans le pom.xml.
Le flag `clean` permet de rebuild enti√®rement l'application, m√™me si aucun morceau de code n'a √©t√© touch√©.

‚ùì What are testcontainers? üá∫üá∏

üí° Les `testcontainers` permettent de r√©aliser des tests unitaires sans avoir √† lancer toute l'application. Leur avantage principale est qu'ils sont portables et l√©ger (car conteneuris√©). üá´üá∑

```yml
name: CI devops 2023
on:
  #to begin you want to launch this job in main and develop
  push:
    branches: [master] 
  pull_request:

jobs:
  test-backend: 
    runs-on: ubuntu-22.04
    steps:
     #checkout your github code using actions/checkout@v2.5.0
      - uses: actions/checkout@v2.5.0

     #do the same with another action (actions/setup-java@v3) that enable to setup jdk 17
      - name: Set up JDK 17
        uses: actions/setup-java@v3
        with:
            java-version: '17'
            distribution: 'temurin'
     #finally build your app with the latest command
      - name: Build and test with Maven
        working-directory: simple-api-student/
        run: mvn clean verify
```

‚ùì Document your Github Actions configurations:

```yml
name: CI devops 2023
on:
  #to begin you want to launch this job in main and develop
  push:
    branches: [master] 
  pull_request:
```

- üí° On pr√©cise √† quel moment lancer les `jobs`. Ici, lors d'un push sur la branche master sur GitHub. On ne lance rien lors d'une pull request. üá´üá∑
``` yml
jobs:
  test-backend: 
    runs-on: ubuntu-22.04
    steps:
     #checkout your github code using actions/checkout@v2.5.0
      - uses: actions/checkout@v2.5.0

     #do the same with another action (actions/setup-java@v3) that enable to setup jdk 17
      - name: Set up JDK 17
        uses: actions/setup-java@v3
        with:
            java-version: '17'
            distribution: 'temurin'
     #finally build your app with the latest command
      - name: Build and test with Maven
        working-directory: simple-api-student/
        run: mvn clean verify
```
- üí° On a ici un seul job, `test-backend`. On pr√©cise son environnements, et les √©tapes qu'il devra suivre. On n'en a ici qu'une seule, compos√©e de trois sous partie. Dans la premi√®re on r√©cup√®re le dernier commit du repo. Dans la deuxi√®me, on set up notre java en indiquant sa version & sa distribution. Enfin, on lance nos tests unitaire avec le `mvn clean verify`. On pr√©cise cependant avant l'emplacement du dossier car le repo contient plusieurs autres projets. üá´üá∑

### First steps into the CD World

Le but de cette partie est de permettre une livraison continue du code. √Ä chaque push, on lance nos batterie de test & on build des images dockers qui sont ensuite publi√© sur dockerhub.

‚ùì Secured Variables, why? üá∫üá∏

üí° Afin de ne pas rendre public des donn√©es sensibles qui pourraient rendre vuln√©rables nos projets (cl√© ssh, identifiant github, identifiant database etc... ). üá´üá∑

On d√©clare donc plusieurs variables secr√®te qu'on pourra acc√©der dans notre `main.yml` public sans qu'elles ne soient √©critent en clair.

Pour build & push sur nos repo dockerhub, on rajoute un `job` √† notre `main.yml`, **build-and-push-docker-image** :

```yml
build-and-push-docker-image:
    needs: test-backend
    # run only when code is compiling and tests are passing
    runs-on: ubuntu-22.04

    # steps to perform in job
    steps:
      - name: Checkout code
        uses: actions/checkout@v2.5.0

      - name: Login to DockerHub
        run: docker login -u ${{ secrets.DOCKERHUB_USERNAME }} -p ${{ secrets.DOCKERHUB_TOKEN }}

      - name: Build image and push backend
        uses: docker/build-push-action@v3
        with:
          # relative path to the place where source code with Dockerfile is located
          context: ./simple-api-student
          # Note: tags has to be all lower-case
          tags:  ${{secrets.DOCKERHUB_USERNAME}}/tp-devops-simple-api:latest
          push: ${{ github.ref == 'refs/heads/master' }}
      # DO the same for database
      - name: Build image and push database
        uses: docker/build-push-action@v3
        with:
          context: ./database
          tags:  ${{secrets.DOCKERHUB_USERNAME}}/tp-database:latest
          push: ${{ github.ref == 'refs/heads/master' }}
      # DO the same for httpd
      - name: Build image and push httpd
        uses: docker/build-push-action@v3
        with:
          context: ./my-apache-server
          tags:  ${{secrets.DOCKERHUB_USERNAME}}/my-apache-server:latest
          push: ${{ github.ref == 'refs/heads/master' }}
```

‚ùìWhy did we put needs: build-and-test-backend on this job?  üá∫üá∏

üí° Il y a un ordre √† respecter car pour build notre image docker, il faut d'abord que notre application est √©t√© compil√©e au pr√©alable. üá´üá∑

‚ùì For what purpose do we need to push docker images? üá∫üá∏

üí° En pushant les images dockers, elles devient r√©cup√©rables depuis n'importe qu'elle docker. Cela peut s'av√©rer tr√®s utile pour pouvoir d√©ployer facilement & rapidement. üá´üá∑

### Setup Quality Gate

**Sonar** : Plateforme de monitoring de code √† des fins d'analyse.

Apr√®s avoir configur√© sonar en le liant au repo GitHub, on ajoute l'analyse dans notre fichier `main.yml` : 

```yml
      - name: Build and test with Maven
        working-directory: simple-api-student/
        run: mvn -B verify sonar:sonar -Dsonar.projectKey=Thomas0507_devOps-TP01 -Dsonar.organization=thomas0507 -Dsonar.host.url=https://sonarcloud.io -Dsonar.login=${{ secrets.SONAR_TOKEN }}
```

Il a fallu rajouter les token sonar √† nos secrets GitHub.

‚ùìDocument your quality gate configuration. üá∫üá∏

üí° On utilise `sonar way`, le quality gate par d√©faut. Le code passe le quality test si :

- Aucun nouveau bug
- Aucune nouvelle vuln√©rabilit√©
- New code has limited technical debt
- Tous les nouveaux `security hotspots` sont couverts
- Assez de test pour couvrir le nouveau code (**> 80 %**)
- Peu de duplication dans le nouveau code (**< 3%**) üá´üá∑

###     Bonus: split pipelines (Optional)

Non r√©alis√© :c

## TP 03 - Ansible üõ∏üõ∏üõ∏

On installe ansible & on lui cr√©e un inventaire √† la racine:

```
mkdir ansible
cd ansible
mkdir inventories
cd inventories
touch setup.yml
```

Contenue du setup.yml:
```
all:
 vars:
   ansible_user: centos
   ansible_ssh_private_key_file: /home/pc/.ssh/id_rsa
 children:
   prod:
     hosts: thomas.marin.takima.cloud
```

On peut maintenant ping:

```
sudo ansible all -i ansible/inventories/setup.yml -m ping
```

R√©ponse:

```
thomas.marin.takima.cloud | SUCCESS => {
    "ansible_facts": {
        "discovered_interpreter_python": "/usr/bin/python"
    },
    "changed": false,
    "ping": "pong"
}
```
V√©rifier la conf:

```
ansible all -i ansible/inventories/setup.yml -m setup -a  "filter=ansible_distribution*"
```
R√©ponse:
```
thomas.marin.takima.cloud | SUCCESS => {
    "ansible_facts": {
        "ansible_distribution": "CentOS",
        "ansible_distribution_file_parsed": true,
        "ansible_distribution_file_path": "/etc/redhat-release",
        "ansible_distribution_file_variety": "RedHat",
        "ansible_distribution_major_version": "7",
        "ansible_distribution_release": "Core",
        "ansible_distribution_version": "7.9",
        "discovered_interpreter_python": "/usr/bin/python"
    },
    "changed": false
}
```

Si on avait httpd install√© sur le serveur ansible, on le d√©sinstalle:

```
ansible all -i ansible/inventories/setup.yml -m yum -a "name=httpd state=absent" --become
```
‚ùì Document your inventory and base commands üá∫üá∏

üí° Inventaire:
- On fournit en variable le chemin vers notre cl√© ssh, et l'utilisateur.
- On fournit l'adresse de notre serveur üá´üá∑

### Playbooks

Cr√©ation d'un fichier playbook.yml:

```
touch ansible/playbook.yml
```

Ping:

```
ansible-playbook -i ansible/inventories/setup.yml ansible/playbook.yml
```


### Advanced Playbooks

```
# Install Docker
- hosts: all
  gather_facts: false
  become: true
  tasks:
    - name: Install device-mapper-persistent-data
      yum:
        name: device-mapper-persistent-data
        state: latest

    - name: Install lvm2
      yum:
        name: lvm2
        state: latest

    - name: add repo docker
      command:
        cmd: sudo yum-config-manager --add-repo=https://download.docker.com/linux/centos/docker-ce.repo

    - name: Install Docker
      yum:
        name: docker-ce
        state: present

    - name: Install python3
      yum:
        name: python3
        state: present

    - name: Install docker with Python 3
      pip:
        name: docker
        executable: pip3
      vars:
        ansible_python_interpreter: /usr/bin/python3

    - name: Make sure Docker is running
      service: name=docker state=started
      tags: docker
```

### Using Roles 

Cr√©er un r√¥le:

```
ansible-galaxy init roles/<NOM_DU_ROLE>
```

Roles :
- app
- database
- docker
- network
- proxy

Chaque sous dossier du dossier roles est un r√¥le & on peut les executer de puis le playbook.yml

Lancer les r√¥les depuis le `playbook.yml`:

```
  roles:
    - app
    - database
    - docker
    - network
    - proxy
```



Notre `playbook.yml` avec les r√¥les :


```yml
# Install Docker
- hosts: all
  gather_facts: false
  become: true
  vars_files:
    - group_vars/var.yml
  roles:
    - docker # install docker
    - network # cr√©er un r√©seau pour les containers
    - database # lance la db
    - app # lance le backend
    - proxy # lance le reverse proxy
```


‚ùì Document your playbook üá∫üá∏

üí° On appel chaque r√¥le afin qu'il execute les t√¢ches qu'il contient. üá´üá∑

### Deploy your App

Apr√®s cr√©ation des r√¥les sp√©cifi√©s, chacun doit ex√©cut√© une t√¢che. Leur ordre est important, il faut donc faire attention. Dans la continuit√© de nos secrets github, il faut rajouter des variables d'environements pour les **urls**, les **noms des containers**, le **r√©seau**,et les **tokens**.

Pour cela, on cr√©e un fichier `group_vars\var.yml` :

```
#db
POSTGRES_CONTAINER: postgres-db
POSTGRES_DB: db
POSTGRES_USER: usr
POSTGRES_PASSWORD: pwd

# docker network
DOCKER_NETWORK: app-network

#backend
API_CONTAINER: springboot-app-container
```
On le chiffre ensuite avec `ansible-vault`:

```bash
ansible-vault encrypt ansible/group_vars/var.yml
```

On nous demande de saisir un mot de passe qui nous sera demander lors du d√©ploiement.

Pour d√©chiffrer:

```yml
ansible-vault decrypt ansible/group_vars/var.yml
```

Les diff√©rentes `tasks` execut√©s par les r√¥les :

- docker :

```yml
- name: Install device-mapper-persistent-data
  yum:
    name: device-mapper-persistent-data
    state: latest

- name: Install lvm2
  yum:
    name: lvm2
    state: latest

- name: add repo docker
  command:
    cmd: sudo yum-config-manager --add-repo=https://download.docker.com/linux/centos/docker-ce.repo

- name: Install Docker
  yum:
    name: docker-ce
    state: present

- name: Install python3
  yum:
    name: python3
    state: present

- name: Install docker with Python 3
  pip:
    name: docker
    executable: pip3
  vars:
    ansible_python_interpreter: /usr/bin/python3

- name: Make sure Docker is running
  service: name=docker state=started
  tags: docker
```
- network :
```yml
- name: Create docker network
  community.docker.docker_network:
    name: "{{ DOCKER_NETWORK }}" 
  vars:
    ansible_python_interpreter: /usr/bin/python3
```
- database :
```yml
- name: Run database
  vars:
    ansible_python_interpreter: /usr/bin/python3
  docker_container:
    name: "{{ POSTGRES_CONTAINER }}"
    image: thomas0507/tp-database:latest
    networks:
      - name: "{{ DOCKER_NETWORK }}"
    env:
      POSTGRES_DB: "{{ POSTGRES_DB }}"
      POSTGRES_USER: "{{ POSTGRES_USER }}"
      POSTGRES_PASSWORD: "{{ POSTGRES_PASSWORD }}"
    volumes:
      - myvolume:/var/lib/postgresql/data
    recreate:
      true
    pull:
      true
```
- app :
```yml
- name: Run Backend API
  vars:
    ansible_python_interpreter: /usr/bin/python3
  docker_container:
    name: "{{ API_CONTAINER }}" 
    image: thomas0507/tp-devops-simple-api:latest
    networks:
      - name: "{{ DOCKER_NETWORK }}" 
    env:
      URL: "{{ POSTGRES_CONTAINER }}:5432" 
      POSTGRES_DB: "{{ POSTGRES_DB }}" 
      POSTGRES_USER: "{{ POSTGRES_USER }}" 
      POSTGRES_PASSWORD: "{{ POSTGRES_PASSWORD }}"
    recreate: true
    pull: true
```
- proxy :
```yml
- name: Run HTTPD
  vars:
    ansible_python_interpreter: /usr/bin/python3
  docker_container:
    name: httpd
    image: thomas0507/my-apache-server:latest
    networks:
      - name: "{{ DOCKER_NETWORK }}" 
    ports:
      - 8080:80
    recreate: true
    pull: true
```

‚ùó On notera que pour certaines t√¢ches, il a fallu pr√©cier l'interpr√©teur python d'ansible en version 3.


‚ùì Document your docker_container tasks configuration. üá∫üá∏

- üí° docker : On Installe toutes les d√©pendances & docker √† l'aide de yum.
- üí° network : On cr√©e un r√©seau docker avec le nom contenue dans le `var.yml` et en pr√©cisant la version de python.
- üí° database : On pr√©ciser la version de python. On r√©cup√®re l'image docker de notre base de donn√©e depuis le dockerhub,  et on lui pr√©cise son r√©seau. On passe en variable d'environnement les log superuser. On pr√©cise l'emplacement de son volume afin de maintenir une persistance des donn√©es. On pr√©cise que l'image sera toujours rebuild & pull depuis le repo docker.
- üí°app : Idem qu'au dessus, on r√©cup√®re l'image docker de dockerhub et on l'instancie avec ses variables d'environnements.
- üí°De m√™me, sauf qu'ici on pr√©cise en plus son port expos√©. üá´üá∑

‚ùó√âtant donn√© qu'on a chiffr√© notre `var.yml`, il faut absolument entr√© le mot de passe de la `vault` lors du d√©ploiement :

```bash
sudo ansible-playbook --ask-vault-pass -i ansible/inventories/setup.yml ansible/playbook.yml
```

### Front and More

‚è≥Ran out of time ‚è≥

